{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Workflow\n",
    "- 1: data (prepare and load)\n",
    "\n",
    "- 2: build model\n",
    "\n",
    "- 3: fitting the model to data (training model)\n",
    "\n",
    "- 4: made predictions, evaluate a model (make an inference)\n",
    "\n",
    "- 5: save and load a model\n",
    "\n",
    "- 6: put all together"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Data (single input dim linear regression)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# known parameters, we are trying to get these\n",
    "\n",
    "weight = 0.7\n",
    "bias = 0.3\n",
    "\n",
    "# inputs\n",
    "X = torch.arange(0, 10, 0.2)\n",
    "Y = weight * X + bias\n",
    "X, Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train and test splits\n",
    "length = len(X)\n",
    "split = int(len(X) * 0.8)\n",
    "X_train, Y_train = X[:split], Y[:split]\n",
    "X_test, Y_test = X[split:], Y[split:]\n",
    "\n",
    "print(X_train, Y_train, X_test, Y_test)\n",
    "print(len(X_train), len(Y_train), len(X_test), len(Y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize data\n",
    "\n",
    "def visualize(X_train=X_train, Y_train=Y_train, X_test=X_test, Y_test=Y_test, predictions=None):\n",
    "    plt.scatter(X_train, Y_train, c='blue', label='training data')\n",
    "    plt.scatter(X_test, Y_test, c='green', label='testing data')\n",
    "\n",
    "    if predictions is not None:\n",
    "        plt.scatter(X_test, predictions, c='red', label='predictions')\n",
    "    \n",
    "    plt.legend()\n",
    "\n",
    "visualize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot predictions w/ random weight, bias\n",
    "rand_weight = torch.rand(size=[1])\n",
    "rand_bias = torch.rand(size=[1])\n",
    "print(f'rand_weight: {rand_weight}')\n",
    "print(f'rand_bias: {rand_bias}')\n",
    "\n",
    "predictions = rand_weight * X_test + rand_bias\n",
    "\n",
    "visualize(predictions=predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Build model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.rand(2, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Single Linear Regression Model\n",
    "\n",
    "class SingleLinearRegressionModel(nn.Module): ## all models/neural networks inherit from nn.Module\n",
    "    \n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.weights = nn.Parameter(torch.randn(1, requires_grad=True, dtype=torch.float32))\n",
    "        self.bias = nn.Parameter(torch.randn(1, requires_grad=True, dtype=torch.float32))  \n",
    "        #requires_grad means you can change this parameter through gradient descent\n",
    "    \n",
    "    def forward(self, X) -> torch.Tensor:       #When using nn.Parameter, must override the forward() method\n",
    "        return self.weights * X + self.bias\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 42\n",
    "torch.manual_seed(seed=SEED)\n",
    "\n",
    "model = SingleLinearRegressionModel()\n",
    "print(model)\n",
    "print(list(model.parameters()))\n",
    "\n",
    "state_dict = dict(model.state_dict())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Test w/ model's current parameters\n",
    "#MAKE inferences with torch.inference_mode\n",
    "\n",
    "with torch.inference_mode(): #in inference mode, machine doesn't need resources such as requires_grad\n",
    "    preds = model(X_test)\n",
    "print(preds.requires_grad)\n",
    "visualize(predictions=preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Train Model\n",
    "\n",
    "move from unknown parameters (ours are random rn), to known parameters\n",
    "\n",
    "from a poor representation of data to a more accurate representation of the data\n",
    "\n",
    "Need to get loss function in order to use gradient descent to minimize the loss function\n",
    "\n",
    "loss function/cost function/criterion\n",
    "\n",
    "Train:\n",
    "* **Loss Function:** funciton to measure inaccuracy of your model's outputs (from Torch.nn's loss functions)\n",
    "* **Optimizer:** Adjusts the model's parameters to minimize loss function\n",
    "\n",
    "**Learning Rate:**\n",
    "*THe smaller the learning rate, the smaller the changes in the model parameters, (changes are more precise)\n",
    "*The bigger the learning rate, the less precise the changes in the model parameters. Larger changes in parameters\n",
    "\n",
    "Our current model only has 2 parameters, one weight and one bias\n",
    "\n",
    "\n",
    "for pytorch:\n",
    "* Training Loop\n",
    "* Testing Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
